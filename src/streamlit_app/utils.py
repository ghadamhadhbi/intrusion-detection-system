import json
import pickle
import pandas as pd
import numpy as np
from pathlib import Path
import streamlit as st

def load_model(model_path):
    """
    Charge un mod√®le depuis un fichier pickle ou keras
    
    Args:
        model_path (str): Chemin vers le fichier du mod√®le
        
    Returns:
        model: Le mod√®le charg√©
    """
    try:
        if model_path.endswith('.pkl'):
            with open(model_path, 'rb') as f:
                return pickle.load(f)
        elif model_path.endswith('.keras') or model_path.endswith('.h5'):
            from tensorflow import keras
            return keras.models.load_model(model_path)
        else:
            raise ValueError(f"Format de mod√®le non support√©: {model_path}")
    except Exception as e:
        st.error(f"Erreur lors du chargement du mod√®le: {str(e)}")
        return None

def load_metrics(metrics_path="C:/Users/ghada/intrusion-detection-system/data/models/metrics.json"):
    """
    Charge les m√©triques depuis un fichier JSON
    
    Args:
        metrics_path (str): Chemin vers le fichier de m√©triques
        
    Returns:
        dict: Dictionnaire contenant les m√©triques
    """
    try:
        with open(metrics_path, 'r') as f:
            return json.load(f)
    except FileNotFoundError:
        st.warning(f"Fichier de m√©triques non trouv√©: {metrics_path}")
        return {}
    except json.JSONDecodeError:
        st.error(f"Erreur de lecture du fichier JSON: {metrics_path}")
        return {}

def save_metrics(metrics, metrics_path="data/models/metrics.json"):
    """
    Sauvegarde les m√©triques dans un fichier JSON
    
    Args:
        metrics (dict): Dictionnaire contenant les m√©triques
        metrics_path (str): Chemin vers le fichier de m√©triques
    """
    try:
        with open(metrics_path, 'w') as f:
            json.dump(metrics, f, indent=4)
        st.success(f"M√©triques sauvegard√©es dans {metrics_path}")
    except Exception as e:
        st.error(f"Erreur lors de la sauvegarde des m√©triques: {str(e)}")

def load_data(data_path, nrows=None):
    """
    Charge des donn√©es depuis un fichier CSV
    
    Args:
        data_path (str): Chemin vers le fichier CSV
        nrows (int, optional): Nombre de lignes √† charger
        
    Returns:
        DataFrame: Les donn√©es charg√©es
    """
    try:
        if data_path.endswith('.csv'):
            return pd.read_csv(data_path, nrows=nrows)
        elif data_path.endswith('.parquet'):
            return pd.read_parquet(data_path)
        else:
            raise ValueError(f"Format de donn√©es non support√©: {data_path}")
    except Exception as e:
        st.error(f"Erreur lors du chargement des donn√©es: {str(e)}")
        return None

def get_available_models(models_path="data/models"):
    """
    Liste tous les mod√®les disponibles dans le r√©pertoire
    
    Args:
        models_path (str): Chemin vers le r√©pertoire des mod√®les
        
    Returns:
        list: Liste des noms de fichiers de mod√®les
    """
    try:
        path = Path(models_path)
        models = []
        
        # Chercher les fichiers .pkl et .keras
        for ext in ['*.pkl', '*.keras', '*.h5']:
            models.extend([f.name for f in path.glob(ext)])
        
        return sorted(models)
    except Exception as e:
        st.error(f"Erreur lors de la liste des mod√®les: {str(e)}")
        return []

def get_available_datasets(data_path="data/processed"):
    """
    Liste tous les datasets disponibles
    
    Args:
        data_path (str): Chemin vers le r√©pertoire des donn√©es
        
    Returns:
        list: Liste des noms de fichiers de donn√©es
    """
    try:
        path = Path(data_path)
        datasets = []
        
        # Chercher les fichiers .csv et .parquet
        for ext in ['*.csv', '*.parquet']:
            datasets.extend([f.name for f in path.glob(ext)])
        
        return sorted(datasets)
    except Exception as e:
        st.error(f"Erreur lors de la liste des datasets: {str(e)}")
        return []

def calculate_metrics(y_true, y_pred):
    """
    Calcule les m√©triques de performance
    
    Args:
        y_true: Vraies √©tiquettes
        y_pred: Pr√©dictions
        
    Returns:
        dict: Dictionnaire contenant les m√©triques
    """
    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
    
    return {
        'accuracy': accuracy_score(y_true, y_pred),
        'precision': precision_score(y_true, y_pred, average='weighted', zero_division=0),
        'recall': recall_score(y_true, y_pred, average='weighted', zero_division=0),
        'f1_score': f1_score(y_true, y_pred, average='weighted', zero_division=0)
    }

def preprocess_features(data, feature_columns=None):
    """
    Pr√©traitement des features pour la pr√©diction
    
    Args:
        data (DataFrame): Donn√©es √† pr√©traiter
        feature_columns (list): Liste des colonnes de features
        
    Returns:
        array: Features pr√©trait√©es
    """
    try:
        if feature_columns:
            data = data[feature_columns]
        
        # Suppression des valeurs manquantes
        data = data.fillna(0)
        
        # Conversion en numpy array
        return data.values
    except Exception as e:
        st.error(f"Erreur lors du pr√©traitement: {str(e)}")
        return None

def format_metric(value, metric_type='percentage'):
    """
    Formate une m√©trique pour l'affichage
    
    Args:
        value (float): Valeur de la m√©trique
        metric_type (str): Type de m√©trique ('percentage', 'number', 'decimal')
        
    Returns:
        str: M√©trique format√©e
    """
    if metric_type == 'percentage':
        return f"{value * 100:.2f}%"
    elif metric_type == 'number':
        return f"{value:,}"
    elif metric_type == 'decimal':
        return f"{value:.4f}"
    else:
        return str(value)

def generate_alert(attack_type, severity, source_ip, timestamp):
    """
    G√©n√®re une alerte format√©e
    
    Args:
        attack_type (str): Type d'attaque d√©tect√©e
        severity (str): S√©v√©rit√© de l'attaque
        source_ip (str): Adresse IP source
        timestamp (str): Horodatage
        
    Returns:
        dict: Alerte format√©e
    """
    severity_icons = {
        'Critique': 'üî¥',
        'Haute': 'üü†',
        'Moyenne': 'üü°',
        'Faible': 'üü¢'
    }
    
    return {
        'icon': severity_icons.get(severity, '‚ö™'),
        'attack_type': attack_type,
        'severity': severity,
        'source_ip': source_ip,
        'timestamp': timestamp
    }

def get_attack_description(attack_type):
    """
    Retourne une description de l'attaque
    
    Args:
        attack_type (str): Type d'attaque
        
    Returns:
        str: Description de l'attaque
    """
    descriptions = {
        'DoS/DDoS': 'Attaque par d√©ni de service visant √† rendre un service indisponible',
        'Port Scan': 'Balayage des ports pour identifier les services vuln√©rables',
        'Brute Force': 'Tentatives r√©p√©t√©es pour deviner des mots de passe',
        'SQL Injection': 'Injection de code SQL malveillant dans les requ√™tes',
        'Botnet': 'Activit√© coordonn√©e de machines infect√©es',
        'Data Exfiltration': 'Tentative de vol de donn√©es sensibles'
    }
    
    return descriptions.get(attack_type, 'Type d\'attaque inconnu')

def create_confusion_matrix_plot(y_true, y_pred, labels=None):
    """
    Cr√©e un graphique de matrice de confusion
    
    Args:
        y_true: Vraies √©tiquettes
        y_pred: Pr√©dictions
        labels: Noms des classes
        
    Returns:
        plotly figure: Graphique de la matrice de confusion
    """
    from sklearn.metrics import confusion_matrix
    import plotly.figure_factory as ff
    
    cm = confusion_matrix(y_true, y_pred)
    
    if labels is None:
        labels = [str(i) for i in range(len(cm))]
    
    fig = ff.create_annotated_heatmap(
        z=cm,
        x=labels,
        y=labels,
        colorscale='Blues',
        showscale=True
    )
    
    fig.update_layout(
        title='Matrice de Confusion',
        xaxis_title='Pr√©dictions',
        yaxis_title='Vraies √âtiquettes'
    )
    
    return fig